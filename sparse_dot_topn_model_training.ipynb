{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "_path = os.path.abspath(os.path.join(\".\", \"..\", \"..\"))\n",
    "sys.path.append(_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import sparse_dot_topn\n",
    "import re\n",
    "\n",
    "from entity_matching.utilities.ngram_analyzer import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_pickle(filename):\n",
    "    with open(filename, \"rb\") as fn:\n",
    "        return pickle.load(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_from = 2\n",
    "n_to = 4\n",
    "\n",
    "df_max = 0.5\n",
    "\n",
    "model_suffix = f\"n{n_from}_{n_to}_tf_l2_{df_max}\"\n",
    "model_suffix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/mnt/data/mediascreen/sharedfolder/em/hrns_clean.gzip')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons = df[df['hrn_type'] == 'PERSON']\n",
    "df_entities = df[df['hrn_type'] == 'ENTITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons[df_persons['hrn_id'] == 'F_100000']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.) Persons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a) full name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_name_variations = [['last_name'],\n",
    "                        ['first_name', 'last_name'],\n",
    "                        ['last_name', 'first_name'],\n",
    "                        ['middle_name', 'last_name'],\n",
    "                        ['first_name', 'middle_name', 'last_name']\n",
    "                       ]\n",
    "\n",
    "def possible_full_names(_input):\n",
    "    input_dict = dict(zip(('first_name', 'middle_name', 'last_name'), _input))\n",
    "    res = []\n",
    "    for v in full_name_variations:\n",
    "        name_var = [input_dict[i] for i in v if input_dict[i]]\n",
    "        name_var = ' '.join(name_var)\n",
    "        res.append(name_var)\n",
    "    \n",
    "    res = list(set(res))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = ('matt', '', 'baniar')\n",
    "possible_full_names(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with mp.Pool(mp.cpu_count()-2) as pool:\n",
    "    df_persons['possible_full_names'] = pool.map(possible_full_names, zip(df_persons['first_name'], df_persons['middle_name'], df_persons['last_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "full_names_df = df_persons.reset_index()[['record_id', 'hrn_id', 'possible_full_names']].explode('possible_full_names').groupby(['hrn_id', 'possible_full_names'])[['record_id']].agg(min).reset_index()\n",
    "full_names_df = full_names_df.groupby('possible_full_names')[['hrn_id', 'record_id']].agg({'hrn_id': list, 'record_id': list}).reset_index().rename(columns={'possible_full_names':'name', 'hrn_id': 'ids', 'record_id': 'record_ids'})\n",
    "full_names_df = full_names_df[full_names_df['name'] != ''].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_names_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_names_df.to_pickle('/mnt/data/mediascreen/sharedfolder/em/models/full_names_df.pkl', compression= 'gzip')\n",
    "\n",
    "# full_names_df = pd.read_pickle(\"/mnt/data/mediascreen/sharedfolder/em/models/full_names_df.pkl\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams('matt baniar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_func = partial(ngrams, ngram_from=n_from, ngram_to=n_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer_fullname = TfidfVectorizer(\n",
    "    max_df=df_max,\n",
    "    analyzer=ngrams_func,\n",
    "    use_idf=False,\n",
    "    norm='l2'\n",
    ")\n",
    "\n",
    "X_fullname = vectorizer_fullname.fit_transform( full_names_df['name'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer_fullname, open(f'/mnt/data/mediascreen/sharedfolder/em/models/vectorizer_fullname_{model_suffix}.pkl', 'wb'), protocol=4)\n",
    "pickle.dump(X_fullname, open(f'/mnt/data/mediascreen/sharedfolder/em/models/X_fullname_{model_suffix}.pkl', 'wb'), protocol=4)\n",
    "\n",
    "# vectorizer_fullname = load_from_pickle(f\"/mnt/data/mediascreen/sharedfolder/em/models/vectorizer_fullname_{model_suffix}.pkl\")\n",
    "# X_fullname = load_from_pickle(f\"/mnt/data/mediascreen/sharedfolder/em/models/X_fullname_{model_suffix}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import rand\n",
    "from sparse_dot_topn import awesome_cossim_topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_dot_search(full_matrix, search_vector):\n",
    "    cos_top_n = awesome_cossim_topn(full_matrix, search_vector.transpose(), 1, 0.5, use_threads=True, n_jobs=30)\n",
    "    shortlist = zip(cos_top_n.data, cos_top_n.nonzero()[0])\n",
    "    \n",
    "    res = [sorted(shortlist, key=lambda x: -x[0])]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "input_name = 'Felix Patasse'\n",
    "\n",
    "search_features_vec = vectorizer_fullname.transform([input_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_features_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "shortlist_name = sparse_dot_search(X_fullname, search_features_vec)\n",
    "\n",
    "len(shortlist_name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlist_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sparse_results(shortlist_, df_):\n",
    "    s = shortlist_[0]\n",
    "    ss_ids = [int(i[1]) for i in s]\n",
    "    ss_dists = [i[0] for i in s]\n",
    "\n",
    "    ss_df = pd.DataFrame({'id': ss_ids, 'score': ss_dists}).astype({'id': 'int32'}).set_index('id')\n",
    "\n",
    "    res = df_[df_.index.isin(ss_ids)].copy()\n",
    "    res = res.join(ss_df)\n",
    "\n",
    "    res = res.sort_values(by='score', ascending=True)[['score', 'ids']].explode('ids').rename(columns={'ids': 'id'})\n",
    "\n",
    "    res = res.groupby('id').agg({'score': np.max}).sort_values(by='score', ascending=False).astype(float).reset_index()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_sparse_results(shortlist_name, full_names_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons[df_persons['hrn_id'] == 'F_10183']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b) first+last name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "first_names_df = df_persons.reset_index()[['record_id', 'hrn_id', 'first_name']].groupby(['hrn_id', 'first_name'])[['record_id']].agg(min).reset_index()\n",
    "first_names_df = first_names_df.groupby('first_name')[['hrn_id', 'record_id']].agg({'hrn_id': list, 'record_id': list}).reset_index().rename(columns={'first_name':'name', 'hrn_id': 'ids', 'record_id': 'record_ids'})\n",
    "first_names_df = first_names_df[first_names_df['name'] != ''].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "last_names_df = df_persons.reset_index()[['record_id', 'hrn_id', 'last_name']].groupby(['hrn_id', 'last_name'])[['record_id']].agg(min).reset_index()\n",
    "last_names_df = last_names_df.groupby('last_name')[['hrn_id', 'record_id']].agg({'hrn_id': list, 'record_id': list}).reset_index().rename(columns={'last_name':'name', 'hrn_id': 'ids', 'record_id': 'record_ids'})\n",
    "last_names_df = last_names_df[last_names_df['name'] != ''].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(first_names_df)\n",
    "len(last_names_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_names_df.to_pickle('/mnt/data/mediascreen/sharedfolder/em/models/first_names_df.pkl', compression= 'gzip')\n",
    "last_names_df.to_pickle('/mnt/data/mediascreen/sharedfolder/em/models/last_names_df.pkl', compression= 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer_firstname = TfidfVectorizer(\n",
    "    max_df=df_max,\n",
    "    analyzer=ngrams_func,\n",
    "    use_idf=False,\n",
    "    norm='l2'\n",
    ")\n",
    "\n",
    "X_firstname = vectorizer_firstname.fit_transform( first_names_df['name'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer_lastname = TfidfVectorizer(\n",
    "    max_df=df_max,\n",
    "    analyzer=ngrams_func,\n",
    "    use_idf=False,\n",
    "    norm='l2'\n",
    ")\n",
    "\n",
    "X_lastname = vectorizer_lastname.fit_transform( last_names_df['name'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer_firstname, open(f'/mnt/data/mediascreen/sharedfolder/em/models/vectorizer_firstname_{model_suffix}.pkl', 'wb'), protocol=4)\n",
    "pickle.dump(X_firstname, open(f'/mnt/data/mediascreen/sharedfolder/em/models/X_firstname_{model_suffix}.pkl', 'wb'), protocol=4)\n",
    "\n",
    "pickle.dump(vectorizer_lastname, open(f'/mnt/data/mediascreen/sharedfolder/em/models/vectorizer_lastname_{model_suffix}.pkl', 'wb'), protocol=4)\n",
    "pickle.dump(X_lastname, open(f'/mnt/data/mediascreen/sharedfolder/em/models/X_lastname_{model_suffix}.pkl', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "first_name = 'Ange Felix'\n",
    "\n",
    "search_features_vec = vectorizer_firstname.transform([first_name])\n",
    "shortlist_first_name = sparse_dot_search(X_firstname, search_features_vec)\n",
    "\n",
    "len(shortlist_first_name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lastname = 'Patasse'\n",
    "\n",
    "search_features_vec = vectorizer_lastname.transform([lastname])\n",
    "shortlist_lastname = sparse_dot_search(X_lastname, search_features_vec)\n",
    "\n",
    "len(shortlist_lastname[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata as ud\n",
    "\n",
    "latin_letters= {}\n",
    "\n",
    "def is_latin(uchr):\n",
    "    try: return latin_letters[uchr]\n",
    "    except KeyError:\n",
    "         return latin_letters.setdefault(uchr, 'LATIN' in ud.name(uchr))\n",
    "\n",
    "def only_roman_chars(unistr):\n",
    "    return all(is_latin(uchr)\n",
    "           for uchr in unistr\n",
    "           if uchr.isalpha())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with mp.Pool(mp.cpu_count()-2) as pool:\n",
    "    df_entities['entity_check'] = pool.map(only_roman_chars, df_entities['entity_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "entities_df = df_entities.reset_index()[['record_id', 'hrn_id', 'entity_name']].groupby(['hrn_id', 'entity_name'])[['record_id']].agg(min).reset_index()\n",
    "entities_df = entities_df.groupby('entity_name')[['hrn_id', 'record_id']].agg({'hrn_id': list, 'record_id': list}).reset_index().rename(columns={'entity_name':'name', 'hrn_id': 'ids', 'record_id': 'record_ids'})\n",
    "entities_df = entities_df[entities_df['name'] != ''].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df.to_pickle('/mnt/data/mediascreen/sharedfolder/em/models/entities_df.pkl', compression= 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_func_e = partial(ngrams, ngram_from=n_from, ngram_to=n_to, clear_digits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer_entities = TfidfVectorizer(\n",
    "    max_df=df_max,\n",
    "    analyzer=ngrams_func_e,\n",
    "    use_idf=False,\n",
    "    norm='l2'\n",
    ")\n",
    "\n",
    "X_entities = vectorizer_entities.fit_transform( entities_df['name'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer_entities, open(f'/mnt/data/mediascreen/sharedfolder/em/models/vectorizer_entities_{model_suffix}.pkl', 'wb'), protocol=4)\n",
    "pickle.dump(X_entities, open(f'/mnt/data/mediascreen/sharedfolder/em/models/X_entities_{model_suffix}.pkl', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry_em",
   "language": "python",
   "name": "poetry_em"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
